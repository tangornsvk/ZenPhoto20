# This is source file for creating a robots.txt file to
# keep webbots from finding duplicate or invalid content in
# your gallery.
#
# See: http://www.robotstxt.org/ for details on robots.txt.
#
# Place it in the root folder of your web pages.

User-agent: *
Crawl-delay: 30

Disallow: /*/albums/
Allow: /cache*/
Allow: /*/cache*/
Disallow: /backup/
Disallow: /*/backup/
Disallow: /plugins/
Disallow: /*/plugins/
Disallow: /themes/
Disallow: /*/themes/
Disallow: /zp*/
Disallow: /*/zp*/
Disallow: /uploaded/
Disallow: /*/uploaded/
Disallow: /page/search/
Disallow: /*/page/search/

# Link to the sitemap file if using the sitemap-extended plugin.
# Insert your domain and uncomment the line to use it:
# sitemap: %FULLWEBPATH%/cache_html/sitemap/sitemapindex.xml

